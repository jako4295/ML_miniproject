{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from torch.utils.data import DataLoader\n",
    "import methods_NN\n",
    "import torch\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plot setup\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "register_matplotlib_converters()\n",
    "plt.rc(\"figure\", figsize=(12, 8))\n",
    "plt.rc(\"font\", size=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dim_type: str) -> list[np.array]:\n",
    "    match dim_type.lower():\n",
    "        case \"full\":\n",
    "            file_names = [\n",
    "                \"data/trn_all.csv\",\n",
    "                \"data/tst_all.csv\",\n",
    "            ]\n",
    "        case \"pca2\":\n",
    "            file_names = [\n",
    "                \"data/trn_pca2.csv\",\n",
    "                \"data/tst_pca2.csv\",\n",
    "            ]\n",
    "        case \"pca10\":\n",
    "            file_names = [\n",
    "                \"data/trn_pca10.csv\",\n",
    "                \"data/tst_pca10.csv\",\n",
    "            ]\n",
    "        case other:\n",
    "            raise KeyError(\"dim_type must be: 'full', 'pca2', or 'pca10'\")\n",
    "    \n",
    "    file_names += [\"data/trn_labs.csv\", \"data/tst_labs.csv\"]\n",
    "    \n",
    "    return (pd.read_csv(f).to_numpy() for f in file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep\n",
    "# data_train.__len__() -> 2, 2, 2, 3, 3, 3, 7, 151\n",
    "# data_test.__len__() -> 2, 2, 2, 3, 7, 151\n",
    "batch_size = 151\n",
    "\n",
    "data_train, data_test, label_train, label_test = load_data(\"full\")\n",
    "\n",
    "label_train_reshaped = np.zeros((len(label_train), 2))\n",
    "label_test_reshaped = np.zeros((len(label_test), 2))\n",
    "for i, (trn, tst) in enumerate(zip(label_train, label_test)):\n",
    "    label_train_reshaped[i, int(trn)] = 1\n",
    "    label_test_reshaped[i, int(tst)] = 1\n",
    "\n",
    "data_train = methods_NN.NumbersDataset(data_train, label_train_reshaped)\n",
    "data_test = methods_NN.NumbersDataset(data_test, label_train_reshaped)\n",
    "\n",
    "loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "loader_test = DataLoader(data_test, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, hidden_layer_dims: list[int], input_size: int, device: torch.device) -> None:\n",
    "        super(Network, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.relu = nn.ReLU().to(device)\n",
    "        self.l1 = nn.Linear(input_size, hidden_layer_dims[0]).to(device)\n",
    "        self.ln = nn.Linear(hidden_layer_dims[-1], 2).to(device)\n",
    "        self.ls = [self.l1]\n",
    "        \n",
    "        for i in range(len(hidden_layer_dims) - 1):\n",
    "            self.ls.append(\n",
    "                nn.Linear(hidden_layer_dims[i], hidden_layer_dims[i+1]).to(device)\n",
    "            )\n",
    "        self.ls.append(self.ln)\n",
    "        \n",
    "    def forward(self, x: np.array) -> np.array:\n",
    "        out = self.relu(self.ls[0](x))\n",
    "        for l in self.ls[1:-1]:\n",
    "            out = self.relu(l(out))\n",
    "        out = self.ls[-1](out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "epochs = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prep\n",
    "model = Network(\n",
    "    hidden_layer_dims=[100, 250, 500, 250, 100, 10],\n",
    "    input_size=21,\n",
    "    device=device\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:42<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Train the data\n",
    "num_steps = len(loader_train)\n",
    "loss_list = list()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i, (value, label) in enumerate(loader_train):\n",
    "        sample = value.reshape(batch_size, -1).to(device)\n",
    "        label = label.view(label.shape[0], 2).to(device)\n",
    "        \n",
    "        # forward\n",
    "        output = model(sample)\n",
    "        loss = criterion(output, label)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data\n",
    "with torch.no_grad():\n",
    "    out_list = []\n",
    "    label_list = []\n",
    "    n_samples = 0\n",
    "    n_diff = 0\n",
    "    \n",
    "    for value, label in loader_test:\n",
    "        sample = value.to(device)\n",
    "        label = label.view(label.shape[0], 2).to(device)\n",
    "        label_list += label.tolist()\n",
    "        \n",
    "        output = model(sample)\n",
    "        out_list += output.tolist()\n",
    "        n_diff += torch.mean(torch.abs(output-label))\n",
    "        n_samples += 1\n",
    "    \n",
    "    acc = n_diff/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out_list, '*', label='Guess')\n",
    "plt.plot(label_list, '*', label='Truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('uni_python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d0e7ea10070f6431a0e05222e22743ca58b4802c37683723f9594d63bbb8f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
